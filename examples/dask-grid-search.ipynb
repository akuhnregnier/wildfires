{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Different Approaches to Hyperparameter Optimisation using Dask\n",
    "\n",
    "## The approaches covered in this notebook\n",
    "\n",
    "This table presents the covered approaches in the order they should be considered in.\n",
    "With an increasing index, the amount of _potential_ parallelism (see suitability and applicability) increases, thereby potentially increasing performance.\n",
    "\n",
    "| Index | Name                             | Implementation         | Underlying Complexity | Applicability                                                            | Suitability                                          | Parallelism     | Overhead | Working |\n",
    "|-------|----------------------------------|------------------------|-----------------------|--------------------------------------------------------------------------|------------------------------------------------------|-----------------|----------|---------|\n",
    "|   1   | Dask-ML GridSearchCV             | Dask-ML                | Low                   | Estimators with **single-threaded**<br /> `fit()` methods                | $$n_{\\text{fits}} \\gg n_{\\text{cores}}$$             | Low             | Low      | Yes     |\n",
    "|   2   | Sequantial Fitting               | Dask backend           | Low                   | Estimators with **multi-threaded**<br />`fit()` (and `score()` methods)  | $$n_{\\text{estimators}} \\gg n_{\\text{cores}}$$       | Low*            | High     | Yes     |\n",
    "|   3   | `GridSearchCV` Modification      | Custom `GridSearchCV`  | Medium                | Estimators with **multi-threaded**<br /> `fit()` (and `score()` methods) | $$n_{\\text{fits}} \\gg n_{\\text{workers}}$$           | Medium          | Medium   | Yes     |\n",
    "|   4   | Custom RF Implementation         | Custom RF              | High                  | `RandomForestRegressor`                                                  | $$n_{\\text{tree-fits}} \\gg n_{\\text{cores}}$$        | High            | High     | Yes     |\n",
    "|   5   | Native scikit-learn GridSearchCV | Dask backend           | Low                   | General                                                                  | $$n_{\\text{fits}} \\gg n_{\\text{cores}}$$             | High            | High     | No      |\n",
    "\n",
    "\\* For a single call to `fit()` this method would deserve a parallelism of 'High', but since each subsequent call needs to wait for the previous call to finish, a lot of time is potentially wasted when the suitability criterion $n_{\\text{estimators}} \\gg n_{\\text{cores}}$ is not satisfied.\n",
    "\n",
    "### Terminology\n",
    "  - $n_{\\text{estimators}}$ is the number of estimators (per forest)\n",
    "  - $n_{\\text{fits}} = n_{\\text{parameters}} \\times n_{\\text{splits}}$ \n",
    "  - $n_{\\text{tree-fits}} = n_{\\text{fits}} \\times n_{\\text{estimators}}$ \n",
    "  - $n_{\\text{workers}}$ is the number of Dask workers\n",
    "  - $n_{\\text{cores}}$ is the total number of cores available for all Dask workers\n",
    "  \n",
    "Note that $n_{\\text{workers}} \\le n_{\\text{cores}}$, determining the ordering between 2 and 4.\n",
    "\n",
    "### Example timing\n",
    "\n",
    "#### Setup\n",
    "\n",
    " - $n$ workers (see table below)\n",
    "   - LocalCluster (ie. low worker-worker and worker-scheduler latency and high bandwidth)\n",
    "   - 5 threads per worker\n",
    " - Local scoring with 1 thread (for methods 2 & 4)\n",
    "   - Method 2 does it sequentially after each fit\n",
    "   - Method 4 carries out scoring asynchronously\n",
    " - `X` with shape `(int(2e5), 40)`\n",
    " - `y` with shape `(int(2e5),)`\n",
    " - The estimator used was the `RandomForestRegressor`\n",
    " - k-Fold cross-validation using 5 folds\n",
    " \n",
    "The following parameters were used:\n",
    "```python\n",
    "parameters_RF = {\n",
    "    \"n_estimators\": [50],\n",
    "    \"max_depth\": [6, 9, 12],\n",
    "    \"min_samples_split\": [2],\n",
    "    \"min_samples_leaf\": [1, 5, 10],\n",
    "}\n",
    "\n",
    "default_param_dict = {\n",
    "    \"random_state\": 1,\n",
    "    \"bootstrap\": True,\n",
    "    \"max_features\": \"auto\",\n",
    "}\n",
    "```\n",
    "\n",
    "#### Timing results\n",
    "\n",
    "| Index | Name                             | $$n_{workers}=3$$ Time (s) / (% of total) / Fraction of min                    | $$n_{workers}=5$$ Time (s) / (% of total) / Fraction of min |\n",
    "|-------|----------------------------------|--------------------------------------------------------------------------------|-------------------------------------------------------------|\n",
    "|   1   | Dask-ML GridSearchCV             | 932 / 27.6% / 1.22                                                             | 897 / 31.2% / 1.52                                          |\n",
    "|   2   | Sequantial Fitting               | 921 / 27.2% / 1.21                                                             | 678 / 24.0% / 1.15                                          |\n",
    "|   3   | `GridSearchCV` Modification      | 765 / 22.6% / 1.00                                                             | 655 / 23.2% / 1.11                                          |\n",
    "|   4   | Custom RF Implementation         | 763 / 22.6% / 1.00                                                             | 590 / 20.9% / 1.00                                          |\n",
    "|   5   | Native scikit-learn GridSearchCV | N/A                                                                            | N/A                                                         |\n",
    "\n",
    "The ordering in the first table is 'obeyed' as we scale up the cluster, since methods 2-4 become much faster, while method 1 does not.\n",
    "While the method pairs (1,2) and (3,4) performed roughly equally for 3 workers, methods 2 and 4 outperformed methods 1 and 3 respectively as the cluster is scaled up.\n",
    "Note that these results are dependent on the exact workload, of course.\n",
    "The fact that a `LocalCluster` is used here also needs to be taken into account, since a realistic cluster will suffer from reduced bandwidth and increased latency, favouring methods with reduced overhead (reduced communication)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import product\n",
    "from time import time\n",
    "\n",
    "import numpy as np\n",
    "from dask.distributed import Client, as_completed\n",
    "from joblib import parallel_backend\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "class Time:\n",
    "    def __init__(self, name=\"\"):\n",
    "        self.name = name\n",
    "\n",
    "    def __enter__(self):\n",
    "        self.start = time()\n",
    "\n",
    "    def __exit__(self, type, value, traceback):\n",
    "        print(\"Time taken for {}: {}\".format(self.name, time() - self.start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a LocalCluster for demonstration purposes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Used for `score()` on the current node in the case of `fit_dask_rf_grid_search_cv()` (method 4).\n",
    "local_n_jobs = 1\n",
    "\n",
    "threads_per_worker = 5\n",
    "client = Client(\n",
    "    n_workers=3,\n",
    "    threads_per_worker=threads_per_worker,\n",
    "    # This resource specification is required by `DaskGridSearchCV`.\n",
    "    resources={\"threads\": threads_per_worker},\n",
    ")\n",
    "client"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate Different Approaches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Common Parameters and Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the common training and test data.\n",
    "np.random.seed(1)\n",
    "X = np.random.random((int(2e5), 40))\n",
    "y = X[:, 0] + X[:, 1] + np.random.random((X.shape[0],))\n",
    "\n",
    "# Define the number of splits.\n",
    "n_splits = 5\n",
    "kf = KFold(n_splits=n_splits)\n",
    "\n",
    "# Define the parameter space.\n",
    "parameters_RF = {\n",
    "    \"n_estimators\": [50],\n",
    "    \"max_depth\": [6, 9, 12],\n",
    "    \"min_samples_split\": [2],\n",
    "    \"min_samples_leaf\": [1, 5, 10],\n",
    "}\n",
    "\n",
    "default_param_dict = {\n",
    "    \"random_state\": 1,\n",
    "    \"bootstrap\": True,\n",
    "    \"max_features\": \"auto\",\n",
    "}\n",
    "\n",
    "rf_params_list = [\n",
    "    dict(zip(parameters_RF, param_values))\n",
    "    for param_values in product(*parameters_RF.values())\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Dask-ML GridSearchCV\n",
    "\n",
    "This works, but only allocates one thread per **forest fit**, _not per tree_, making for very slow training when $n_{\\text{fits}} \\lt n_{\\text{cores}}$.\n",
    "\n",
    "Use this when $n_{\\text{fits}} \\gg n_{\\text{cores}}$, where $n_{\\text{fits}} = n_{\\text{parameters}} \\times n_{\\text{splits}}$ and $n_{\\text{cores}}$ is the total number of cores available for all Dask workers, or when individual estimator `fit()` calls are only single threaded (**unlike** `RandomForestRegressor.fit()`, which releases the GIL). In the latter case, it doesn't make a difference which method is chosen, since the parallism is inherently limited by the chosen estimator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dask_ml.model_selection import GridSearchCV\n",
    "\n",
    "gs = GridSearchCV(\n",
    "    RandomForestRegressor(**default_param_dict),\n",
    "    parameters_RF,\n",
    "    cv=n_splits,\n",
    "    return_train_score=True,\n",
    "    refit=False,\n",
    ")\n",
    "with Time(\"Dask-ML GridSearchCV\"):\n",
    "    gs = gs.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Individual fits in series\n",
    "\n",
    "Wait for each RF fit to complete (using the Dask backend) and score (using local threading backend, since `predict()` (used by `score()` requires 'sharedmem'!) before starting the next one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_and_score(X, y, train_index, test_index, rf_params):\n",
    "    rf = RandomForestRegressor(**rf_params)\n",
    "    with parallel_backend(\"dask\"):\n",
    "        rf.fit(X[train_index], y[train_index])\n",
    "\n",
    "    with parallel_backend(\"threading\", n_jobs=local_n_jobs):\n",
    "        test_score = rf.score(X[test_index], y[test_index])\n",
    "        train_score = rf.score(X[train_index], y[train_index])\n",
    "\n",
    "    return test_score, train_score\n",
    "\n",
    "\n",
    "rf_params = default_param_dict.copy()\n",
    "\n",
    "test_scores_list = []\n",
    "train_scores_list = []\n",
    "\n",
    "with Time(\"In Series\"):\n",
    "    for rf_grid_params in tqdm(rf_params_list, desc=\"Params\"):\n",
    "        rf_params.update(rf_grid_params)\n",
    "        test_scores = []\n",
    "        train_scores = []\n",
    "        for i, (train_index, test_index) in enumerate(list(kf.split(X))):\n",
    "            test_score, train_score = fit_and_score(\n",
    "                X, y, train_index, test_index, rf_params\n",
    "            )\n",
    "            test_scores.append(test_score)\n",
    "            train_scores.append(train_score)\n",
    "\n",
    "        test_scores_list.append(test_scores)\n",
    "        train_scores_list.append(train_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Modify `GridSearchCV` to fit one forest per worker.\n",
    "\n",
    "Use this when $n_{\\text{fits}} \\gg n_{\\text{workers}}$, where $n_{\\text{fits}} = n_{\\text{parameters}} \\times n_{\\text{splits}}$ and $n_{\\text{workers}}$ is the number of Dask workers.\n",
    "Individual estimator `fit()` and `score()` calls should be multithreaded.\n",
    "\n",
    "This uses Dask `resources`. See here for further information regarding this use case:\n",
    " - https://github.com/dask/dask-jobqueue/issues/181\n",
    " - https://github.com/dask/dask-jobqueue/issues/231\n",
    " \n",
    "Using this approach seems to prevent work stealing from working properly, resulting in _new_ workers not being allocated existing work:\n",
    " - https://github.com/dask/distributed/issues/1851\n",
    "\n",
    "A workaround seems to be to wait for _all_ desired workers to be registered to the scheduler before starting to submit work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from wildfires.dask_cx1 import DaskGridSearchCV\n",
    "\n",
    "gs = DaskGridSearchCV(\n",
    "    RandomForestRegressor(**default_param_dict),\n",
    "    parameters_RF,\n",
    "    cv=n_splits,\n",
    "    return_train_score=True,\n",
    "    refit=False,\n",
    "    verbose=10,\n",
    ")\n",
    "with Time(\"Custom Single-Workers Dask GridsearchCV\"):\n",
    "    gs = gs.dask_fit(client, X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Define our own RF implementation that submits individual trees as Dask tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from wildfires.dask_cx1 import DaskRandomForestRegressor, fit_dask_rf_grid_search_cv\n",
    "\n",
    "with Time(\"Custom Dask grid search\"):\n",
    "    results = fit_dask_rf_grid_search_cv(\n",
    "        DaskRandomForestRegressor(**default_param_dict),\n",
    "        X,\n",
    "        y,\n",
    "        n_splits,\n",
    "        parameters_RF,\n",
    "        client,\n",
    "        verbose=True,\n",
    "        return_train_score=True,\n",
    "        refit=False,\n",
    "        local_n_jobs=local_n_jobs,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Native scikit-learn GridSearchCV (fails, e.g. with CancelledError)\n",
    "\n",
    "It is apparent (prior to failing) that this does spread out the training of individual trees, which should have lead to expected speedups when $n_{\\text{fits}} \\lt n_{\\text{workers}}$ (or about the same magnitude).\n",
    "\n",
    "The CancelledError occurrence has already been reported:\n",
    " - https://github.com/scikit-learn/scikit-learn/issues/12315\n",
    " - https://github.com/scikit-learn/scikit-learn/issues/15383\n",
    " - https://github.com/joblib/joblib/issues/959\n",
    " - https://github.com/joblib/joblib/issues/1021"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "gs = GridSearchCV(\n",
    "    RandomForestRegressor(**default_param_dict),\n",
    "    parameters_RF,\n",
    "    cv=n_splits,\n",
    "    return_train_score=True,\n",
    "    refit=False,\n",
    ")\n",
    "with Time(\"Scikit-learn GridSearchCV with Dask\"):\n",
    "    with parallel_backend(\"dask\"):\n",
    "        gs = gs.fit(X, y)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:wildfires] *",
   "language": "python",
   "name": "conda-env-wildfires-python3-ffmpeg"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
