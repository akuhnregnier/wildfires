{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import product\n",
    "from tempfile import TemporaryDirectory\n",
    "from time import time\n",
    "\n",
    "import numpy as np\n",
    "from dask.distributed import Client, as_completed\n",
    "from joblib import parallel_backend\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "from tqdm import tqdm\n",
    "\n",
    "from wildfires.dask_cx1 import get_client\n",
    "from wildfires.logging_config import enable_logging\n",
    "\n",
    "enable_logging(level=\"debug\")\n",
    "\n",
    "\n",
    "class Time:\n",
    "    def __init__(self, name=\"\"):\n",
    "        self.name = name\n",
    "\n",
    "    def __enter__(self):\n",
    "        self.start = time()\n",
    "\n",
    "    def __exit__(self, type, value, traceback):\n",
    "        print(\"Time taken for {}: {}\".format(self.name, time() - self.start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a LocalCluster for demonstration purposes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Used for local scoring.\n",
    "local_n_jobs = 1\n",
    "\n",
    "threads_per_worker = 3\n",
    "client = Client(n_workers=1, threads_per_worker=threads_per_worker,)\n",
    "client"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Or use an existing distributed cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Used for local scoring.\n",
    "local_n_jobs = 32\n",
    "\n",
    "client = get_client()\n",
    "client"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Common Parameters and Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the common training and test data.\n",
    "np.random.seed(1)\n",
    "X = np.random.random((int(1e3), 40))\n",
    "y = X[:, 0] + X[:, 1] + np.random.random((X.shape[0],))\n",
    "\n",
    "# Define the number of splits.\n",
    "n_splits = 5\n",
    "kf = KFold(n_splits=n_splits)\n",
    "\n",
    "# Define the parameter space.\n",
    "parameters_RF = {\n",
    "    \"n_estimators\": [50],\n",
    "    \"max_depth\": [6, 9, 12],\n",
    "    \"min_samples_split\": [2],\n",
    "    \"min_samples_leaf\": [1, 5, 10],\n",
    "}\n",
    "\n",
    "default_param_dict = {\n",
    "    \"random_state\": 1,\n",
    "    \"bootstrap\": True,\n",
    "    \"max_features\": \"auto\",\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cached Timed Dask RF Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from wildfires.dask_cx1 import (\n",
    "    DaskRandomForestRegressor,\n",
    "    fit_dask_sub_est_random_search_cv,\n",
    ")\n",
    "\n",
    "with Time(\"Custom Dask random grid search\"):\n",
    "    with TemporaryDirectory() as tempdir:\n",
    "        for _ in range(3):\n",
    "            results, fit_est = fit_dask_sub_est_random_search_cv(\n",
    "                DaskRandomForestRegressor(**default_param_dict),\n",
    "                X,\n",
    "                y,\n",
    "                parameters_RF,\n",
    "                client,\n",
    "                n_splits=n_splits,\n",
    "                max_time=\"6s\",\n",
    "                n_iter=None,\n",
    "                verbose=True,\n",
    "                refit=True,\n",
    "                return_train_score=True,\n",
    "                local_n_jobs=local_n_jobs,\n",
    "                random_state=0,\n",
    "                cache_dir=tempdir,\n",
    "            )\n",
    "            print(\"Nr. of results:\", len(results))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:wildfires] *",
   "language": "python",
   "name": "conda-env-wildfires-py"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
