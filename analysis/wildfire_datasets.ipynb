{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "from copy import copy, deepcopy\n",
    "from functools import partial, reduce\n",
    "from itertools import islice\n",
    "from pprint import pprint\n",
    "\n",
    "import cartopy.crs as ccrs\n",
    "import iris\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from wildfires.analysis.plotting import cube_plotting\n",
    "from wildfires.data.cube_aggregation import Datasets, prepare_selection\n",
    "from wildfires.data.datasets import (\n",
    "    MCD64CMQ_C6,\n",
    "    CCI_BurnedArea_MERIS_4_1,\n",
    "    CCI_BurnedArea_MODIS_5_1,\n",
    "    GFEDv4,\n",
    "    GFEDv4s,\n",
    "    regions_GFED,\n",
    ")\n",
    "from wildfires.utils import get_masked_array, get_ncpus, get_unmasked\n",
    "from wildfires.utils import land_mask as get_land_mask\n",
    "from wildfires.utils import match_shape, polygon_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fire_datasets = Datasets(\n",
    "    map(\n",
    "        lambda fire_dataset: fire_dataset(),\n",
    "        (GFEDv4s, GFEDv4, CCI_BurnedArea_MODIS_5_1, MCD64CMQ_C6,),\n",
    "    )\n",
    ").select_variables(\n",
    "    [\"CCI MODIS BA\", \"GFED4 BA\", \"GFED4s BA\", \"MCD64CMQ BA\",]\n",
    ") + Datasets(\n",
    "    CCI_BurnedArea_MERIS_4_1()\n",
    ").select_variables(\n",
    "    \"CCI MERIS BA\"\n",
    ")\n",
    "\n",
    "monthly, mean, climatology = prepare_selection(fire_datasets, which=\"all\")\n",
    "pprint(list(monthly))\n",
    "\n",
    "land_mask = ~get_land_mask()\n",
    "\n",
    "no_fire_mask = np.all(\n",
    "    reduce(\n",
    "        np.logical_and,\n",
    "        map(partial(np.isclose, b=0), (cube.data for cube in monthly.cubes)),\n",
    "    ),\n",
    "    axis=0,\n",
    ")\n",
    "\n",
    "for fire_datasets in (monthly, mean, climatology):\n",
    "    fire_datasets.homogenise_masks()\n",
    "    for cube in fire_datasets.cubes:\n",
    "        cube.data.mask |= reduce(\n",
    "            np.logical_or,\n",
    "            map(\n",
    "                partial(match_shape, target_shape=cube.shape), (land_mask, no_fire_mask)\n",
    "            ),\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = reduce(\n",
    "    np.logical_and, map(partial(np.isclose, b=0), (cube.data for cube in monthly.cubes))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for cube, name in zip(monthly.cubes, monthly.pretty_variable_names):\n",
    "    print(name, np.unique(np.mean(cube.data.mask, axis=0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mpl.rc(\"figure\", figsize=(14, 6))\n",
    "for cube, name in zip(mean.cubes, mean.pretty_variable_names):\n",
    "    m = cube.collapsed(\n",
    "        (\"latitude\", \"longitude\"),\n",
    "        iris.analysis.MEAN,\n",
    "        weights=iris.analysis.cartography.area_weights(cube),\n",
    "    ).data\n",
    "    cube_plotting(cube, log=True, title=name + f\" {m:0.5f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Seasonality\n",
    "\n",
    "Seasonal variation of the different datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regions = regions_GFED()\n",
    "# Skip region index 0, ie. the ocean.\n",
    "for region_index in islice(regions.attributes[\"regions\"], 1, None):\n",
    "    region_name = regions.attributes[\"regions\"][region_index]\n",
    "    region_mask = regions.data != region_index\n",
    "    fig = plt.figure(figsize=(20, 8))\n",
    "    axes = (plt.subplot(1, 2, 1), plt.subplot(1, 2, 2, projection=ccrs.Robinson()))\n",
    "    for cube, name in zip(\n",
    "        deepcopy(climatology.cubes), climatology.pretty_variable_names\n",
    "    ):\n",
    "        cube.data.mask |= match_shape(region_mask, cube.shape)\n",
    "        with warnings.catch_warnings():\n",
    "            warnings.filterwarnings(\"ignore\", message=r\".*DEFAULT.*\")\n",
    "            axes[0].plot(\n",
    "                range(1, 13),\n",
    "                cube.collapsed(\n",
    "                    (\"latitude\", \"longitude\"),\n",
    "                    iris.analysis.MEAN,\n",
    "                    weights=iris.analysis.cartography.area_weights(cube),\n",
    "                ).data,\n",
    "                label=name,\n",
    "            )\n",
    "    axes[0].legend(loc=\"best\")\n",
    "    axes[0].set_ylabel(\"Average Burned Area Fraction\")\n",
    "    axes[0].set_xlabel(\"Month\")\n",
    "    axes[0].set_yscale(\"log\")\n",
    "    vis_cube = deepcopy(mean.cubes[0])\n",
    "    vis_cube.data.mask |= region_mask\n",
    "    if np.all(vis_cube.data.mask):\n",
    "        print(f\"No data for {region_name}\")\n",
    "    else:\n",
    "        cube_plotting(vis_cube, ax=axes[1], log=True, title=region_name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:wildfires]",
   "language": "python",
   "name": "conda-env-wildfires-py"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
