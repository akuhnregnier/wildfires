{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import logging.config\n",
    "import os\n",
    "import pickle\n",
    "from copy import deepcopy\n",
    "\n",
    "import iris\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm\n",
    "\n",
    "from wildfires.analysis.plotting import (\n",
    "    cube_plotting,\n",
    "    map_model_output,\n",
    "    partial_dependence_plot,\n",
    ")\n",
    "from wildfires.analysis.processing import filling, log_map, log_modulus, map_name, vif\n",
    "from wildfires.data.cube_aggregation import aggregate_cubes\n",
    "from wildfires.data.datasets import DATA_DIR, data_map_plot\n",
    "from wildfires.logging_config import LOGGING\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "logging.config.dictConfig(LOGGING)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normal_size = 9.0\n",
    "normal_coast_linewidth = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aggregate_cubes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_mapping(key):\n",
    "    if \"log\" in key:\n",
    "        return False\n",
    "    if key.lower() in {\"monthly burned area\", \"popd\"}:\n",
    "        return True\n",
    "    if \" \".join(key.lower().split(\" \")[1:]) in {\"monthly burned area\", \"popd\"}:\n",
    "        return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print dataset time information.\n",
    "from wildfires.data.datasets import *\n",
    "\n",
    "datasets = [\n",
    "    AvitabileThurnerAGB(),\n",
    "    CHELSA(),\n",
    "    Copernicus_SWI(),\n",
    "    ESA_CCI_Landcover_PFT(),\n",
    "    GFEDv4(),\n",
    "    GSMaP_precipitation(),\n",
    "    GSMaP_dry_day_period(),\n",
    "    GlobFluo_SIF(),\n",
    "    HYDE(),\n",
    "    LIS_OTD_lightning_time_series(),\n",
    "    Liu_VOD(),\n",
    "    MOD15A2H_LAI_fPAR(),\n",
    "    Simard_canopyheight(),\n",
    "    Thurner_AGB(),\n",
    "]\n",
    "min_time, max_time, times_df = dataset_times(datasets)\n",
    "# print(times_df)\n",
    "print(times_df.to_latex(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(DATA_DIR, \"mean_cubes.pickle\"), \"rb\") as f:\n",
    "    mean_cubes = pickle.load(f)\n",
    "print(mean_cubes)\n",
    "# so that analysis below can be replicated for other kinds of cubes\n",
    "cubes = mean_cubes\n",
    "# Get land mask from the data.\n",
    "land_cube = cubes.extract_strict(iris.Constraint(name=\"pftNoLand\"))\n",
    "land_mask = np.isclose(land_cube.data.data, 1.0)\n",
    "mpl.rcParams[\"figure.figsize\"] = (8, 5)\n",
    "fig = cube_plotting(land_mask.astype(\"int64\"), title=\"Land Mask\", cmap=\"Reds_r\")\n",
    "\n",
    "# Remove the land mask cube from the CubeList\n",
    "del cubes[cubes.index(land_cube)]\n",
    "\n",
    "filename = os.path.expanduser(os.path.join(\"~/tmp/to_send\", \"land_mask\" + \".pdf\"))\n",
    "print(\"Saving to {}\".format(filename))\n",
    "fig.savefig(filename, dpi=dpi, bbox_inches=\"tight\", transparent=True, rasterised=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a latitude mask which ignores data beyond 60 degrees, as the precipitation data does not extend to those latitudes.\n",
    "lats = cubes[0].coord(\"latitude\").points\n",
    "lons = cubes[1].coord(\"longitude\").points\n",
    "lat_mask = np.meshgrid(lats, lons, indexing=\"ij\")[0] > 60\n",
    "\n",
    "lat_land_cubes = deepcopy(cubes)\n",
    "\n",
    "for cube in lat_land_cubes:\n",
    "    cube.data.mask[lat_mask] = True\n",
    "    cube.data.mask[land_mask] = True\n",
    "\n",
    "n_cols = 4\n",
    "n_plots = len(lat_land_cubes)\n",
    "\n",
    "mpl.rcParams[\"figure.figsize\"] = (20, 12)\n",
    "\n",
    "fig, axes = plt.subplots(\n",
    "    nrows=int(np.ceil(float(n_plots) / n_cols)), ncols=n_cols, squeeze=False\n",
    ")\n",
    "axes = axes.flatten()\n",
    "for (i, (ax, feature)) in enumerate(zip(axes, range(n_plots))):\n",
    "    ax.hist(\n",
    "        lat_land_cubes[feature].data.data[~lat_land_cubes[feature].data.mask],\n",
    "        density=True,\n",
    "        bins=70,\n",
    "    )\n",
    "    ax.set_xlabel(lat_land_cubes[feature].name())\n",
    "    ax.set_yscale(\"log\")\n",
    "\n",
    "for ax in axes[n_plots:]:\n",
    "    ax.set_axis_off()\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get names of all the cubes we have access to.\n",
    "from pprint import pprint\n",
    "\n",
    "pprint([c.name() for c in lat_land_cubes])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figsize = (5, 3.8)\n",
    "dpi = 600\n",
    "mpl.rcParams[\"figure.figsize\"] = figsize\n",
    "mpl.rcParams[\"font.size\"] = normal_size\n",
    "\n",
    "cube = lat_land_cubes.extract_strict(iris.Constraint(name=\"monthly burned area\"))\n",
    "fig = cube_plotting(\n",
    "    cube,\n",
    "    cmap=\"Reds\",\n",
    "    log=True,\n",
    "    label=\"ln(Fraction)\",\n",
    "    title=\"Log Mean Burned Area (GFEDv4)\",\n",
    "    coastline_kwargs={\"linewidth\": normal_coast_linewidth},\n",
    ")\n",
    "filename = os.path.expanduser(\n",
    "    os.path.join(\"~/tmp/to_send\", cube.name().replace(\" \", \"_\") + \".pdf\")\n",
    ")\n",
    "print(\"Saving to {}\".format(filename))\n",
    "fig.savefig(filename, dpi=dpi, bbox_inches=\"tight\", transparent=True, rasterised=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figsize = (4, 2.7)\n",
    "dpi = 600\n",
    "mpl.rcParams[\"figure.figsize\"] = figsize\n",
    "mpl.rcParams[\"font.size\"] = normal_size\n",
    "\n",
    "cube = lat_land_cubes.extract_strict(iris.Constraint(name=\"AGBtree\"))\n",
    "fig = cube_plotting(\n",
    "    cube,\n",
    "    cmap=\"viridis\",\n",
    "    log=True,\n",
    "    label=r\"kg m$^{-2}$\",\n",
    "    title=\"AGBtree\",\n",
    "    coastline_kwargs={\"linewidth\": normal_coast_linewidth},\n",
    ")\n",
    "filename = os.path.expanduser(\n",
    "    os.path.join(\"~/tmp/to_send\", cube.name().replace(\" \", \"_\") + \".pdf\")\n",
    ")\n",
    "print(\"Saving to {}\".format(filename))\n",
    "fig.savefig(filename, dpi=dpi, bbox_inches=\"tight\", transparent=True, rasterised=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cubes_mod = filling(cubes, land_mask, lat_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mpl.rcParams[\"figure.figsize\"] = (8, 5)\n",
    "fig = cube_plotting(\n",
    "    cubes_mod.extract_strict(\n",
    "        iris.Constraint(name=\"monthly burned area\")\n",
    "    ).data.mask.astype(\"int64\"),\n",
    "    title=\"Land Mask\",\n",
    "    cmap=\"Reds_r\",\n",
    ")\n",
    "\n",
    "filename = os.path.expanduser(os.path.join(\"~/tmp/to_send\", \"land_mask2\" + \".pdf\"))\n",
    "print(\"Saving to {}\".format(filename))\n",
    "fig.savefig(filename, dpi=dpi, bbox_inches=\"tight\", transparent=True, rasterised=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figsize = (4, 2.7)\n",
    "dpi = 600\n",
    "mpl.rcParams[\"figure.figsize\"] = figsize\n",
    "mpl.rcParams[\"font.size\"] = normal_size\n",
    "\n",
    "cube = cubes_mod.extract_strict(iris.Constraint(name=\"AGBtree\"))\n",
    "fig = cube_plotting(\n",
    "    cube,\n",
    "    cmap=\"viridis\",\n",
    "    log=True,\n",
    "    label=r\"kg m$^{-2}$\",\n",
    "    title=\"AGBtree (interpolated)\",\n",
    "    coastline_kwargs={\"linewidth\": normal_coast_linewidth},\n",
    ")\n",
    "filename = os.path.expanduser(\n",
    "    os.path.join(\n",
    "        \"~/tmp/to_send\", cube.name().replace(\" \", \"_\") + \"_interpolated\" + \".pdf\"\n",
    "    )\n",
    ")\n",
    "print(\"Saving to {}\".format(filename))\n",
    "fig.savefig(filename, dpi=dpi, bbox_inches=\"tight\", transparent=True, rasterised=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "burned_area_cube = cubes_mod.extract_strict(iris.Constraint(name=\"monthly burned area\"))\n",
    "endog_data = pd.Series(burned_area_cube.data.data[~burned_area_cube.data.mask])\n",
    "names = []\n",
    "data = []\n",
    "for cube in cubes_mod:\n",
    "    if cube.name() != \"monthly burned area\":\n",
    "        names.append(cube.name())\n",
    "        data.append(cube.data.data[~cube.data.mask].reshape(-1, 1))\n",
    "\n",
    "exog_data = pd.DataFrame(np.hstack(data), columns=names)\n",
    "\n",
    "exog_data[\"temperature range\"] = (\n",
    "    exog_data[\"maximum temperature\"] - exog_data[\"minimum temperature\"]\n",
    ")\n",
    "del exog_data[\"minimum temperature\"]\n",
    "\n",
    "print(\"Names before:\")\n",
    "print(exog_data.columns)\n",
    "\n",
    "# Carry out log transformation for select variables.\n",
    "log_var_names = [\"temperature range\", \"dry_days\", \"dry_day_period\"]\n",
    "\n",
    "for name in log_var_names:\n",
    "    mod_data = exog_data[name] + 0.01\n",
    "    assert np.all(mod_data >= (0.01 - 1e-8)), \"{:}\".format(name)\n",
    "    exog_data[\"log \" + name] = np.log(mod_data)\n",
    "    del exog_data[name]\n",
    "\n",
    "# Carry out square root transformation\n",
    "sqrt_var_names = [\"Combined Flash Rate Time Series\", \"popd\"]\n",
    "for name in sqrt_var_names:\n",
    "    assert np.all(exog_data[name] >= 0), \"{:}\".format(name)\n",
    "    exog_data[\"sqrt \" + name] = np.sqrt(exog_data[name])\n",
    "    del exog_data[name]\n",
    "\n",
    "print(\"Names after:\")\n",
    "print(exog_data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vifs = vif(exog_data)\n",
    "print(vifs.to_string(index=False, float_format=\"{:0.1f}\".format))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thres = 6\n",
    "vifs.loc[\n",
    "    vifs[\"Name\"] == \"Fraction of Absorbed Photosynthetically Active Radiation\", \"Name\"\n",
    "] = \"FAPAR\"\n",
    "print(\n",
    "    vifs.loc[vifs[\"VIF\"] < thres].to_latex(index=False, float_format=\"{:0.1f}\".format)\n",
    ")\n",
    "print(\n",
    "    vifs.loc[vifs[\"VIF\"] >= thres].to_latex(index=False, float_format=\"{:0.1f}\".format)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove redundant variables.\n",
    "exog_data2 = deepcopy(exog_data)\n",
    "for key in (\n",
    "    \"Soil Water Index with T=100\",\n",
    "    \"Fraction of Absorbed Photosynthetically Active Radiation\",\n",
    "    \"Leaf Area Index\",\n",
    "    \"precip\",\n",
    "    \"pftBare\",\n",
    "    \"TreeAll\",\n",
    "    \"log dry_days\",\n",
    "):\n",
    "    del exog_data2[key]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vifs2 = vif(exog_data2)\n",
    "print(vifs2.to_string(index=False, float_format=\"{:0.1f}\".format))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thres = 6\n",
    "print(\n",
    "    vifs2.loc[vifs2[\"VIF\"] < thres].to_latex(index=False, float_format=\"{:0.1f}\".format)\n",
    ")\n",
    "print(\n",
    "    vifs2.loc[vifs2[\"VIF\"] >= thres].to_latex(\n",
    "        index=False, float_format=\"{:0.1f}\".format\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = sm.GLM(endog_data, exog_data2, family=sm.families.Binomial())\n",
    "model_results = model.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model_results.summary())\n",
    "print(\"R2:\", r2_score(y_true=endog_data, y_pred=model_results.fittedvalues))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figsize = (4, 2.7)\n",
    "dpi = 600\n",
    "mpl.rcParams[\"figure.figsize\"] = figsize\n",
    "mpl.rcParams[\"font.size\"] = normal_size\n",
    "\n",
    "plt.figure()\n",
    "plt.hexbin(endog_data, model_results.fittedvalues, bins=\"log\")\n",
    "plt.xlabel(\"real data\")\n",
    "plt.ylabel(\"prediction\")\n",
    "plt.colorbar()\n",
    "\n",
    "filename = os.path.expanduser(os.path.join(\"~/tmp/to_send\", \"hexbin_GLM1\" + \".pdf\"))\n",
    "print(\"Saving to {}\".format(filename))\n",
    "plt.savefig(filename, dpi=dpi, bbox_inches=\"tight\", transparent=True, rasterised=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data generation.\n",
    "global_mask = burned_area_cube.data.mask\n",
    "\n",
    "# Predicted burned area values.\n",
    "ba_predicted = np.zeros_like(global_mask, dtype=np.float64)\n",
    "ba_predicted[~global_mask] = model_results.fittedvalues\n",
    "ba_predicted = np.ma.MaskedArray(ba_predicted, mask=global_mask)\n",
    "\n",
    "# Observed values.\n",
    "ba_data = np.zeros_like(global_mask, dtype=np.float64)\n",
    "ba_data[~global_mask] = endog_data.values\n",
    "ba_data = np.ma.MaskedArray(ba_data, mask=global_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting of burned area data & predictions:\n",
    "#  - ba_predicted: predicted burned area\n",
    "#  - ba_data: observed\n",
    "#  - model_name: Name for titles AND filenames\n",
    "model_name = \"GLMv1\"\n",
    "figs = map_model_output(\n",
    "    ba_predicted, ba_data, model_name, normal_size, normal_coast_linewidth\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figsize = (5, 3)\n",
    "dpi = 600\n",
    "mpl.rcParams[\"figure.figsize\"] = figsize\n",
    "mpl.rcParams[\"font.size\"] = normal_size\n",
    "\n",
    "columns = list(map(map_name, exog_data2.columns))\n",
    "\n",
    "\n",
    "def get_trim_func(n=10, cont_str=\"...\"):\n",
    "    def trim(string):\n",
    "        if len(string) > n:\n",
    "            string = string[: n - len(cont_str)]\n",
    "            string += cont_str\n",
    "        return string\n",
    "\n",
    "    return trim\n",
    "\n",
    "\n",
    "# https://stackoverflow.com/questions/55289921/matplotlib-matshow-xtick-labels-on-top-and-bottom/55289968\n",
    "n = len(columns)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "corr_arr = np.ma.MaskedArray(exog_data2.corr().values)\n",
    "corr_arr.mask = np.zeros_like(corr_arr)\n",
    "# Ignore diagnals, since they will all be 1 anyway!\n",
    "np.fill_diagonal(corr_arr.mask, True)\n",
    "\n",
    "im = ax.matshow(corr_arr, interpolation=\"none\")\n",
    "\n",
    "fig.colorbar(im, pad=0.04, shrink=0.95)\n",
    "\n",
    "ax.set_xticks(np.arange(n))\n",
    "ax.set_xticklabels(map(get_trim_func(), columns))\n",
    "ax.set_yticks(np.arange(n))\n",
    "ax.set_yticklabels(columns)\n",
    "\n",
    "# Set ticks on top of axes on\n",
    "ax.tick_params(axis=\"x\", bottom=False, top=True, labelbottom=False, labeltop=True)\n",
    "# Rotate and align bottom ticklabels\n",
    "# plt.setp([tick.label1 for tick in ax.xaxis.get_major_ticks()], rotation=45,\n",
    "#          ha=\"right\", va=\"center\", rotation_mode=\"anchor\")\n",
    "# Rotate and align top ticklabels\n",
    "plt.setp(\n",
    "    [tick.label2 for tick in ax.xaxis.get_major_ticks()],\n",
    "    rotation=45,\n",
    "    ha=\"left\",\n",
    "    va=\"center\",\n",
    "    rotation_mode=\"anchor\",\n",
    ")\n",
    "\n",
    "# For some reason the code below does not work and produces overallping top labels.\n",
    "# Maybe needed to set the rotation_mode, ha, and va parameters from above?\n",
    "# plt.xticks(range(len(columns)), map(get_trim_func(), columns), rotation=45)\n",
    "# plt.yticks(range(len(columns)), columns)\n",
    "# plt.colorbar(pad=0.2)\n",
    "\n",
    "# ax.set_title(\"Correlation Matrix\", pad=40)\n",
    "fig.tight_layout()\n",
    "\n",
    "filename = os.path.expanduser(\n",
    "    os.path.join(\"~/tmp/to_send\", \"correlation_GLM1\" + \".pdf\")\n",
    ")\n",
    "print(\"Saving to {}\".format(filename))\n",
    "fig.savefig(filename, dpi=dpi, bbox_inches=\"tight\", transparent=True, rasterised=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model_results.summary().as_latex())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest\n",
    "## Using same data as for the GLMv1 above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regr = RandomForestRegressor(n_estimators=100, random_state=1)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    exog_data2, endog_data, random_state=1, shuffle=True, test_size=0.3\n",
    ")\n",
    "regr.fit(X_train, y_train)\n",
    "print(\"R2 train:\", regr.score(X_train, y_train))\n",
    "print(\"R2 test:\", regr.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_mask = burned_area_cube.data.mask\n",
    "\n",
    "ba_predicted = np.zeros_like(global_mask, dtype=np.float64)\n",
    "ba_predicted[~global_mask] = regr.predict(exog_data2)\n",
    "ba_predicted = np.ma.MaskedArray(ba_predicted, mask=global_mask)\n",
    "\n",
    "ba_data = np.zeros_like(global_mask, dtype=np.float64)\n",
    "ba_data[~global_mask] = endog_data\n",
    "ba_data = np.ma.MaskedArray(ba_data, mask=global_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting of burned area data & predictions:\n",
    "#  - ba_predicted: predicted burned area\n",
    "#  - ba_data: observed\n",
    "#  - model_name: Name for titles AND filenames\n",
    "model_name = \"RFv1\"\n",
    "figs = map_model_output(\n",
    "    ba_predicted, ba_data, model_name, normal_size, normal_coast_linewidth\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mpl.rcParams[\"figure.figsize\"] = (20, 12)\n",
    "mpl.rcParams[\"font.size\"] = 18\n",
    "fig, axes = partial_dependence_plot(\n",
    "    regr,\n",
    "    X_test,\n",
    "    X_test.columns,\n",
    "    n_cols=4,\n",
    "    grid_resolution=70,\n",
    "    coverage=0.5,\n",
    "    predicted_name=\"burned area\",\n",
    ")\n",
    "plt.subplots_adjust(wspace=0.16)\n",
    "_ = list(ax.axes.get_yaxis().set_ticks([]) for ax in axes)\n",
    "\n",
    "filename = os.path.expanduser(os.path.join(\"~/tmp/to_send\", \"pdp_RFv1\" + \".pdf\"))\n",
    "print(\"Saving to {}\".format(filename))\n",
    "fig.savefig(filename, dpi=dpi, bbox_inches=\"tight\", transparent=True, rasterised=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################ DOES NOT DEMONSTRATE ANYTHING!! #################\n",
    "lims = []\n",
    "varnames = []\n",
    "for ax in axes:\n",
    "    lims.append(ax.get_ylim()[1])\n",
    "    varnames.append(ax.get_xlabel())\n",
    "for i, j in zip(varnames, exog_data2.columns.values):\n",
    "    assert i == j\n",
    "\n",
    "tvalues = np.abs(model_results.tvalues)\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.plot(lims, tvalues, linestyle=\"\", marker=\"o\")\n",
    "\n",
    "for i, txt in enumerate(varnames):\n",
    "    plt.annotate(txt, (lims[i], tvalues[i]))\n",
    "\n",
    "plt.xlabel(\"RF\")\n",
    "plt.ylabel(\"GLM T Value\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importances = regr.feature_importances_\n",
    "std = np.std([tree.feature_importances_ for tree in regr.estimators_], axis=0)\n",
    "forest_names = list(map(map_name, exog_data2.columns.values))\n",
    "importances_df = pd.DataFrame(\n",
    "    {\n",
    "        \"Name\": forest_names,\n",
    "        \"Importance\": importances,\n",
    "        \"Importance STD\": std,\n",
    "        \"Ratio\": np.array(std) / np.array(importances),\n",
    "    }\n",
    ")\n",
    "print(\n",
    "    importances_df.sort_values(\"Importance\", ascending=False).to_latex(\n",
    "        index=False, float_format=\"{:0.3f}\".format\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating backup slides\n",
    "## First the datasets that were simply selected\n",
    "## Then the datasets after they were modified with NN interpolation and isolated outlier removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figsize = (5, 3.8)\n",
    "dpi = 600\n",
    "mpl.rcParams[\"figure.figsize\"] = figsize\n",
    "mpl.rcParams[\"font.size\"] = normal_size\n",
    "\n",
    "for cube in lat_land_cubes:\n",
    "    fig = cube_plotting(\n",
    "        cube,\n",
    "        log=log_map(cube.name()),\n",
    "        coastline_kwargs={\"linewidth\": normal_coast_linewidth},\n",
    "    )\n",
    "    filename = os.path.expanduser(\n",
    "        os.path.join(\n",
    "            \"~/tmp/to_send\", \"backup_\" + cube.name().replace(\" \", \"_\") + \".pdf\"\n",
    "        )\n",
    "    )\n",
    "    print(\"Saving to {}\".format(filename))\n",
    "    fig.savefig(\n",
    "        filename, dpi=dpi, bbox_inches=\"tight\", transparent=True, rasterised=True\n",
    "    )\n",
    "\n",
    "for cube in cubes_mod:\n",
    "    fig = cube_plotting(\n",
    "        cube,\n",
    "        log=log_map(cube.name()),\n",
    "        coastline_kwargs={\"linewidth\": normal_coast_linewidth},\n",
    "    )\n",
    "    filename = os.path.expanduser(\n",
    "        os.path.join(\n",
    "            \"~/tmp/to_send\", \"backup_mod_\" + cube.name().replace(\" \", \"_\") + \".pdf\"\n",
    "        )\n",
    "    )\n",
    "    print(\"Saving to {}\".format(filename))\n",
    "    fig.savefig(\n",
    "        filename, dpi=dpi, bbox_inches=\"tight\", transparent=True, rasterised=True\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
